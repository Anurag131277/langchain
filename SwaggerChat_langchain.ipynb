{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMbWBCANj3BTGxtDrrBdmpg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Anurag131277/langchain/blob/main/SwaggerChat_langchain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ogqXcuAtQVEU",
        "outputId": "e10b3feb-33ba-431f-8e62-1cc5ceba3251"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.5/140.5 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m423.4/423.4 kB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.2/47.2 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m223.6/223.6 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "%pip install --quiet -U langgraph langchain_community langchain_core langchain_nvidia_ai_endpoints langchain_experimental"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "1ACzL_FLQ7Yi"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "os.environ[\"NVIDIA_API_KEY\"] = userdata.get('NVIDIA_API_KEY')"
      ],
      "metadata": {
        "id": "OBJUURkBRCZX"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm_str= 'meta/llama-3.3-70b-instruct'"
      ],
      "metadata": {
        "id": "-UujvWJ7REnB"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_nvidia_ai_endpoints import ChatNVIDIA\n",
        "# from typing import Any\n",
        "\n",
        "# from langchain.chains.openai_functions.openapi import openapi_spec_to_openai_fn\n",
        "# from langchain_community.utilities.openapi import OpenAPISpec\n",
        "# from langchain_core.prompts import ChatPromptTemplate\n",
        "# from langchain_community.tools.json.tool import JsonSpec\n",
        "# from langchain.chains import APIChain\n",
        "# from langchain_community.agent_toolkits import JsonToolkit,create_json_agent\n",
        "# from langchain_community.agent_toolkits.openapi.spec import reduce_openapi_spec\n",
        "\n",
        "import json\n",
        "import argparse\n",
        "import requests\n",
        "\n",
        "from langchain_community.utilities.requests import RequestsWrapper\n",
        "from langchain_community.agent_toolkits.openapi import planner\n",
        "from langchain_community.agent_toolkits.openapi.spec import reduce_openapi_spec\n",
        "\n",
        "ALLOW_DANGEROUS_REQUEST = True\n"
      ],
      "metadata": {
        "id": "atsnQ8D_RGuI"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# url = 'https://petstore.swagger.io/v2/swagger.json'\n",
        "# url3='https://petstore31.swagger.io/api/v31/openapi.json'\n",
        "# response= requests.get(url3)\n",
        "\n",
        "# payload= response.json()\n",
        "# print(str(payload))\n",
        "\n",
        "\n",
        "with open(\"open_ai.json\") as f:\n",
        "    openapi = json.load(f)"
      ],
      "metadata": {
        "id": "YEhDkxrMRsze"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# llm = ChatNVIDIA(model=llm_str,temperature=0)\n",
        "# parsed_spec=OpenAPISpec.from_url(url3)\n",
        "\n",
        "requests_wrapper = RequestsWrapper()\n",
        "# json_spec = JsonSpec(dict_=payload, max_value_length=4000)\n",
        "# openai_api_spec = reduce_openapi_spec(json_spec)\n",
        "# print(json_spec)"
      ],
      "metadata": {
        "id": "tH3mYemERMbf"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# openai_fns, call_api_fn = openapi_spec_to_openai_fn(json_spec)\n",
        "# json_toolkit = JsonToolkit(spec=json_spec)\n",
        "\n",
        "# json_agent_executor = create_json_agent(\n",
        "#     llm=ChatNVIDIA(model=llm_str,temperature=0), toolkit=json_toolkit, verbose=True\n",
        "# )\n",
        "\n",
        "f1_spec = reduce_openapi_spec(openapi,dereference=False)"
      ],
      "metadata": {
        "id": "eYXxGf9DROLo"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt = ChatPromptTemplate.from_template(\n",
        "#     \"Use the provided APIs to respond to this user query:\\n\\n{query}\"\n",
        "# )"
      ],
      "metadata": {
        "id": "R7tPzneISgbQ"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatNVIDIA(model=llm_str,temperature=0)"
      ],
      "metadata": {
        "id": "qStaWJ8pV0fM"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f1_agent = planner.create_openapi_agent(\n",
        "    f1_spec, requests_wrapper, llm, allow_dangerous_requests=True\n",
        ")"
      ],
      "metadata": {
        "id": "bRg2cL0eWEBw"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_query = \"what is the name of the pet with Id 1\"\n",
        "response = f1_agent.run(user_query)\n",
        "print(f\"response ${response}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wotw6-p0cg-H",
        "outputId": "83d15d23-ab50-437d-ce15-c21f0971154c"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mAction: api_planner\n",
            "Action Input: I need to find the right API calls to get the name of the pet with Id 1\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mTo find the name of the pet with Id 1, we can use the GET endpoint to retrieve the pet's information.\n",
            "\n",
            "Plan: \n",
            "1. GET /pet/1 to retrieve the pet's information, which should include the name of the pet.\n",
            "\n",
            "This single API call should provide the necessary information to solve the user's query.\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mI have a plan to retrieve the pet's information, now I should execute this plan using the api_controller tool to get the actual data.\n",
            "\n",
            "Action: api_controller\n",
            "Action Input: 1. GET /pet/1 to retrieve the pet's information\u001b[0m\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mTo execute the plan, I need to start by retrieving the pet's information using the GET /pet/1 endpoint. This endpoint requires the petId as a path parameter, which in this case is 1.\n",
            "\n",
            "Action: requests_get\n",
            "Action Input: {\"url\": \"https://petstore31.swagger.io/api/v31/pet/1\", \"params\": {}, \"output_instructions\": \"Extract id and name from the response\"}\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mTo accomplish the task based on the provided API response and instructions, we will follow these steps:\n",
            "\n",
            "1. **Check for Error**: First, we need to verify if the response indicates an error. The provided response does not explicitly mention an error, so we proceed with extracting the required information.\n",
            "\n",
            "2. **Extract id and name**: We are tasked with extracting the `id` and `name` from the response. \n",
            "\n",
            "Given the API response:\n",
            "```json\n",
            "{\n",
            "  \"id\": 1,\n",
            "  \"category\": {\n",
            "    \"id\": 2,\n",
            "    \"name\": \"Cats\"\n",
            "  },\n",
            "  \"name\": \"Cat 1\",\n",
            "  \"photoUrls\": [\n",
            "    \"url1\",\n",
            "    \"url2\"\n",
            "  ],\n",
            "  \"tags\": [\n",
            "    {\n",
            "      \"id\": 1,\n",
            "      \"name\": \"tag1\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": 2,\n",
            "      \"name\": \"tag2\"\n",
            "    }\n",
            "  ],\n",
            "  \"status\": \"available\",\n",
            "  \"availableInstances\": 0,\n",
            "  \"petDetailsId\": 0,\n",
            "  \"petDetails\": {\n",
            "    \"id\": 1,\n",
            "    \"category\": {\n",
            "      \"id\": 2,\n",
            "      \"name\": \"Cats\"\n",
            "    },\n",
            "    \"tag\": {\n",
            "      \"id\": 1,\n",
            "      \"name\": \"tag1\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "```\n",
            "\n",
            "The `id` and `name` that are directly accessible from the root of the JSON object are:\n",
            "- `id`: 1\n",
            "- `name`: Cat 1\n",
            "\n",
            "However, it's also worth noting the `id` and `name` within the `category` and `petDetails` sections, as well as the `tags`, but the primary `id` and `name` as per the instruction are the ones at the root level.\n",
            "\n",
            "**Output**:\n",
            "```json\n",
            "{\n",
            "  \"id\": 1,\n",
            "  \"name\": \"Cat 1\"\n",
            "}\n",
            "```\n",
            "\n",
            "This output follows the instructions by extracting the `id` and `name` from the API response. Since the response does not indicate an error, there's no need to output a summary of an error.\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mThought: I have successfully executed the plan by retrieving the pet's information using the GET /pet/1 endpoint. The response from the API contains the pet's id and name, which I have extracted according to the output instructions. Since the plan only consisted of a single API call, I can now conclude the execution.\n",
            "\n",
            "Final Answer: \n",
            "```json\n",
            "{\n",
            "  \"id\": 1,\n",
            "  \"name\": \"Cat 1\"\n",
            "}\n",
            "```\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "Observation: \u001b[33;1m\u001b[1;3m```json\n",
            "{\n",
            "  \"id\": 1,\n",
            "  \"name\": \"Cat 1\"\n",
            "}\n",
            "```\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mI have executed the plan and retrieved the pet's information, which includes the name of the pet.\n",
            "\n",
            "Final Answer: The name of the pet with Id 1 is \"Cat 1\".\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "response $The name of the pet with Id 1 is \"Cat 1\".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ndf4uQAmcsGc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}